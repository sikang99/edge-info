## LLM : Large Language Model 

- LLM : Large Language Model
- VLM : Vision(Video) Language Model
- VNM : Visual Navigation Model
- ALM : Augmented Language Models
- MMLU : Massive Multitask Language Understanding
- Foundation Model, Big Model
- CoT : Chain of Thought
- SK : Semantic Kernel


### Education
- Standfor : [CS324 - Large Language Models](https://stanford-cs324.github.io/winter2022/)


### Articles
- 2023/03/16 [The Unpredictable Abilities Emerging From Large AI Models](https://www.quantamagazine.org/the-unpredictable-abilities-emerging-from-large-ai-models-20230316)
- 2023/03/16 [Pinecone and OpenAI magic: A guide to finding your long lost blog posts with vectorized search and ChatGPT](https://blog.baeke.info/2023/03/16/pinecone-and-openai-magic-a-guide-to-finding-your-long-lost-blog-posts-with-vectorized-search-and-chatgpt/)
- 2023/03/15 [GPT-4 Designed a Programming Language](https://lukebechtel.com/blog/gpt4-generating-code)
- 2023/03/15 [Meet Petals: An Open-Source Artificial Intelligence (AI) System That Can Run 100B+ Language Models At Home Bit-Torrent Style](https://www.marktechpost.com/2023/03/15/meet-petals-an-open-source-artificial-intelligence-ai-system-that-can-run-100b-language-models-at-home-bit-torrent-style/)
- 2023/03/15 [The Sensitive Side of ChatGPT](https://www.hackster.io/news/the-sensitive-side-of-chatgpt-d2f5fd4fd4d2)
- 2023/03/15 [5 ways GPT-4 outsmarts ChatGPT](https://techcrunch.com/2023/03/14/5-ways-gpt-4-outsmarts-chatgpt/)
- 2023/03/14 [On the Global AI [Il]Literacy: Real AI vs. Fake AI vs. HI](https://www.linkedin.com/pulse/real-ai-vs-fake-which-machine-intelligence-humanity-needs-abdoullaev/)
- 2023/03/14 [Google opens up its AI language model PaLM to challenge OpenAI and GPT-3](https://www.theverge.com/2023/3/14/23639313/google-ai-language-model-palm-api-challenge-openai)
- 2023/03/14 [PaLM API & MakerSuite: an approachable way to start prototyping and building generative AI applications](https://developers.googleblog.com/2023/03/announcing-palm-api-and-makersuite.html)
- 2023/03/08 [Google’s PaLM-E is a generalist robot brain that takes commands](https://arstechnica.com/information-technology/2023/03/embodied-ai-googles-palm-e-allows-robot-control-with-natural-commands/)
- 2023/03/08 [What is a Large Language Model (LLM)?](https://www.mlq.ai/what-is-a-large-language-model-llm/)
- 2023/03/14 [You can now run a GPT-3 level AI model on your laptop, phone, and Raspberry Pi](https://arstechnica.com/information-technology/2023/03/you-can-now-run-a-gpt-3-level-ai-model-on-your-laptop-phone-and-raspberry-pi/)
- 2023/03/13 [Alpaca: A Strong Open-Source Instruction-Following Model](https://crfm.stanford.edu/2023/03/13/alpaca.html)
- 2023/02/28 [Inside LLaMA: Meta AI New Large Language Model that Outperforms GPT-3 Across Many Tasks](https://pub.towardsai.net/inside-llama-meta-ai-new-large-language-model-that-outperforms-gpt-3-across-many-tasks-d1e42f23c804)
- 2023/02/25 [Getting started with LangChain — A powerful tool for working with Large Language Models](https://medium.com/@avra42/getting-started-with-langchain-a-powerful-tool-for-working-with-large-language-models-286419ba0842)
- 2023/02/24 [Introducing LLaMA: A foundational, 65-billion-parameter large language model](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/)
- 2023/02/18 [Understanding Google's GPT-Killer- The Revolutionary Pathways Architecture](https://artificialintelligencemadesimple.substack.com/p/understanding-googles-revolutionary)
- 2023/02/16 [Timeline of AI and language models](https://lifearchitect.ai/timeline/)
- 2023/02/16 [OpenAI GPT-3 vs PaLM: A comparison of capabilities and differences](https://blog.accubits.com/openai-gpt-3-vs-palm-a-comparison-of-capabilities-and-differences/)
- 2023/02/09 [What is Sentient AI and Is it Already Here?](https://www.simplilearn.com/what-is-sentient-ai-article)
- 2023/00/00 ----
- 2022/12/15 [Seven research papers push foundation model boundaries](https://snorkel.ai/seven-research-papers-push-foundation-model-boundaries/)
- 2022/11/14 [The State of Multilingual AI](https://www.ruder.io/state-of-multilingual-ai/)
- 2022/07/28 [Grounding Language Models for Spatial Reasoning](https://julenetxaniz.eus/en/project/spatial-reasoning/)
- 2022/06/22 [DeepMind Trains 80 Billion Parameter AI Vision-Language Model Flamingo](https://www.infoq.com/news/2022/06/deepmind-flamingo-vlm/)
- 2022/06/09 [Generalized Visual Language Models](https://lilianweng.github.io/posts/2022-06-09-vlm/)
- 2022/05/02 [Foundation Models and the Future of Multi-Modal AI](https://lastweekin.ai/p/multi-modal-ai)
- 2022/04/28 [Tackling multiple tasks with a single visual language model](https://www.deepmind.com/blog/tackling-multiple-tasks-with-a-single-visual-language-model)



### Information
- [Prompt Engineering Guide](https://www.promptingguide.ai/)
- [**LangChain**](https://langchain.readthedocs.io/en/latest/#) - 0.0.115
	- [Blog](https://blog.langchain.dev/)
- [HELM](https://crfm.stanford.edu/helm/latest/) - LLM Benchmarks
- [OmniXAI](https://opensource.salesforce.com/OmniXAI/latest/index.html]
- [A Catalog of Transformer Models](https://orkg.org/comparison/R385010/)
- [Large Language Model (LLM)](https://primo.ai/index.php?title=Large_Language_Model_(LLM))
- [Standford Alpaca](https://crfm.stanford.edu/alpaca/)
- [LLaMA: Open and Efficient Foundation Language Models](https://research.facebook.com/publications/llama-open-and-efficient-foundation-language-models/)
- [BLIP-2: A new Visual Language Model by Salesforce](https://wandb.ai/gladiator/BLIP-2/reports/BLIP-2-A-new-Visual-Language-Model-by-Salesforce--VmlldzozNjM0NjYz)
- OpenAI [CLIP: Connecting text and images](https://openai.com/research/clip)
- [PaLM-E: An Embodied Multimodal Language Model](https://palm-e.github.io/)
- [F-VLM: Open-Vocabulary Object Detection upon Frozen Vision and Language Models](https://sites.google.com/view/f-vlm/home)
- [Open-World Object Manipulation using Pre-Trained Vision-Language Models](https://robot-moo.github.io/)
- [Semantic Abstraction: Open-World 3D Scene Understanding from 2D Vision-Language Models](https://semantic-abstraction.cs.columbia.edu/)
- [GPT-4](https://openai.com/research/gpt-4)
	- [GPT-4 Product](https://openai.com/product/gpt-4)
- [Petals](https://petals.ml/)
- [Powerful language models a click away](https://www.forefront.ai/)
- [Guardrails.ai](https://shreyar.github.io/guardrails/)
- [Dalai](https://cocktailpeanut.github.io/dalai/#/) - Run LLaMA on your computer
- [ViperGPT: Visual Inference via Python Execution for Reasoning](https://viper.cs.columbia.edu/)
- [Semantic Kernel](https://devblogs.microsoft.com/semantic-kernel/)



### Videos 
- [한국인공지능아카데미](https://www.youtube.com/@aiacademy131)
- [거꾸로 읽는 AI 이야기](https://www.youtube.com/@gokkulearn)
	- [VLM backbone에 대한 트렌드를 알아보자!](https://www.youtube.com/watch?v=NgxSbyoiQYM)


### Open Source
- [microsoft/semantic-kernel](https://github.com/microsoft/semantic-kernel) - ntegrate cutting-edge LLM technology quickly and easily into your apps
- [GT-RIPL/Awesome-LLM-Robotics](https://github.com/GT-RIPL/Awesome-LLM-Robotics) - A comprehensive list of papers using large language/multi-modal models for Robotics/RL, including papers, codes, and related websites
- [Georgelingzj/up-to-date-Vision-Language-Models](https://github.com/Georgelingzj/up-to-date-Vision-Language-Models) - Up-to-date Vision Language Models collection. Mainly focus on computer vision
- [facebookresearch/llama](https://github.com/facebookresearch/llama) - Inference code for LLaMA models
- [tatsu-lab/stanford_alpaca](https://github.com/tatsu-lab/stanford_alpaca) - Code and documentation to train Stanford's Alpaca models, and generate the data
- [tloen/alpaca-lora](https://github.com/tloen/alpaca-lora) - Code for reproducing the Stanford Alpaca InstructLLaMA result on consumer hardware
- [zengyan-97/X2-VLM](https://github.com/zengyan-97/X2-VLM) - All-In-One VLM: Image + Video + Transfer to Other Languages / Domains
- [ejsalin/vlm-probing](https://github.com/ejsalin/vlm-probing)
- [anysphere/gpt-4-for-code](https://github.com/anysphere/gpt-4-for-code) - Some examples of GPT-4 for code!
- [google-research/google-research](https://github.com/google-research/google-research) 
- [EleutherAI/gpt-neox](https://github.com/EleutherAI/gpt-neox) - An implementation of model parallel autoregressive transformers on GPUs, based on the DeepSpeed library.
- [KarolynW/GPT-4-Snake-AI](https://github.com/KarolynW/GPT-4-Snake-AI) - The project demonstrates how AI can create a simple AI to play the classic Snake game.
- [mithril-security/blindai](https://github.com/mithril-security/blindai) - Confidential AI deployment with secure enclaves
- [Hironsan/awesome-embedding-models](https://github.com/Hironsan/awesome-embedding-models) - A curated list of awesome embedding models tutorials, projects and communities.
- [ShreyaR/guardrails](https://github.com/ShreyaR/guardrails) - Adding guardrails to large language models
- [flairNLP/flair](https://github.com/flairNLP/flair) - A very simple framework for state-of-the-art Natural Language Processing (NLP)
- [FMInference/FlexGen](https://github.com/FMInference/FlexGen) - Running large language models on a single GPU for throughput-oriented scenarios.
- [gbaeke/gpt-vectors](https://github.com/gbaeke/gpt-vectors) 
- [zeno-ml/zeno-evals](https://github.com/zeno-ml/zeno-evals) - Visualize OpenAI Evals with Zeno
- [openai/evals](https://github.com/openai/evals) - 
- [hwchase17/langchain](https://github.com/hwchase17/langchain) - Building applications with LLMs through composability
- [npiv/chatblade](https://github.com/npiv/chatblade) - A CLI Swiss Army Knife for ChatGPT


### Open Source (Embedded)
- [tloen/llama-int8](https://github.com/tloen/llama-int8) - Quantized inference code for LLaMA models
- [ggerganov/llama.cpp](https://github.com/ggerganov/llama.cpp) - Port of Facebook's LLaMA model in C/C++
- [antimatter15/alpaca.cpp](https://github.com/antimatter15/alpaca.cpp) - Locally run an Instruction-Tuned Chat-Style LLM
- [setzer22/llama-rs](https://github.com/setzer22/llama-rs) - Run LLaMA inference on CPU, with Rust 🦀🚀🦙


### Open Source (Go)
- [AlmazDelDiablo/gpt3-5-turbo-go](https://github.com/AlmazDelDiablo/gpt3-5-turbo-go) - Golang client for official API of ChatGPT (GPT-3.5-turbo)
- [sashabaranov/go-openai](https://github.com/sashabaranov/go-openai) - OpenAI ChatGPT, GPT-3, GPT-4, DALL·E, Whisper API wrapper for Go
- [cornelk/llama-go](https://github.com/cornelk/llama-go) - Port of Facebook's LLaMA (Large Language Model Meta AI) in Golang with embedded C/C++


### Papers
- 2023 [GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models](https://arxiv.org/abs/2303.10130)
- 2023 [**Self-planning Code Generation with Large Language Model**](https://arxiv.org/abs/2303.06689)
- 2023 [GPT-4 Technical Report](https://cdn.openai.com/papers/gpt-4.pdf)
- 2023 [Foundation Models for Decision Making: Problems, Methods, and Opportunities](https://arxiv.org/abs/2303.04129)
- 2023 [Transformer models: an introduction and catalog](https://arxiv.org/abs/2302.07730)
- 2023 [Human Action Recognition: A Taxonomy-Based Survey, Updates, and Opportunities](https://www.mdpi.com/1424-8220/23/4/2182)
- 2023 [Augmented Language Models: a Survey](https://arxiv.org/abs/2302.07842)
- 2023 [F-VLM: Open-Vocabulary Object Detection upon Frozen Vision and Language Models](https://arxiv.org/abs/2209.15639)
- 2022 [Constitutional AI: Harmlessness from AI Feedback](https://arxiv.org/abs/2212.08073#)
- 2022 [Vision-Language Pre-Training: Basics, Recent Advances, and Future Trends](https://www.nowpublishers.com/article/Details/CGV-105)
- 2022 [LM-Nav: Robotic Navigation with Large Pre-Trained Models of Language, Vision, and Action](https://arxiv.org/abs/2207.04429)
- 2022 [Talking About Large Language Models](https://arxiv.org/abs/2212.03551)
- 2022 [Flamingo: a Visual Language Model for Few-Shot Learning](https://arxiv.org/abs/2204.14198)
- 2022 [X2-VLM: All-In-One Pre-trained Model For Vision-Language Tasks](https://arxiv.org/abs/2211.12402)
- 2022 [Pre-Trained Word Embedding and Language Model Improve Multimodal Machine Translation: A Case Study in Multi30K](https://ieeexplore.ieee.org/document/9803016)
- 2022 [VLMbench: A Benchmark for Vision-and-Language Manipulation](https://embodied-ai.org/papers/2022/6.pdf)
- 2022 [UL2: Unifying Language Learning Paradigms](https://arxiv.org/abs/2205.05131)
- 2022 [Emergent Abilities of Large Language Models](https://openreview.net/forum?id=yzkSU5zdwD)
- 2021 [PolyViT: Co-training Vision Transformers on Images, Videos and Audio](https://arxiv.org/abs/2111.12993)
